{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from get_method_here import get_method_here, def_model\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuremap Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicherverwaltung einstellen\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "def extract_from_end_until_underscore(input_string):\n",
    "    last_underscore_index = input_string.rfind('_')\n",
    "    if last_underscore_index != -1:\n",
    "        result = input_string[last_underscore_index + 1:]\n",
    "    else:\n",
    "        result = input_string\n",
    "    return result\n",
    "\n",
    "# Lade das Modell\n",
    "def load_model(model_name, model_path, device):\n",
    "    _, _, arch, norm_type, _ = get_method_here(model_name, weights_path=model_path)\n",
    "    model = def_model(arch, model_path, localize=False)\n",
    "    model = model.to(device).eval()\n",
    "    return model, norm_type\n",
    "\n",
    "# Transformationen definieren\n",
    "def get_transform(norm_type):\n",
    "    from normalization import get_list_norm\n",
    "    \n",
    "    transform = []\n",
    "    transform = transform + get_list_norm(norm_type)\n",
    "    return transforms.Compose(transform)\n",
    "\n",
    "# Benutzerdefinierte Colormap definieren\n",
    "def get_custom_cmap():\n",
    "    colors = [(0, 'green'), (0.5, 'white'), (1, 'red')]\n",
    "    n_bins = 100  # Discretizes the interpolation into bins\n",
    "    cmap_name = 'custom_cmap'\n",
    "    cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
    "    return cmap\n",
    "\n",
    "# Ausgabekarte berechnen und visualisieren\n",
    "def visualize_output_map(model, img_path, transform, device):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    input_img = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Modell ausführen\n",
    "    output = model(input_img).squeeze().cpu().detach().numpy()\n",
    "    print(output.shape)\n",
    "\n",
    "    # Wertebereich für die Ausgabekarte festlegen\n",
    "    vmin, vmax = -200, 200\n",
    "\n",
    "    # Originalbild und Ausgabekarte visualisieren\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "\n",
    "    fig.text(0.5, 0.79, f'Modellausgabe für {extract_from_end_until_underscore(img_path)}', ha='center', fontsize=20)\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Originalbild', fontsize=16)\n",
    "\n",
    "    im = ax[1].imshow(output, cmap=get_custom_cmap(), vmin=vmin, vmax=vmax, alpha=0.5)\n",
    "    ax[1].set_title('Modellausgabe (Featuremap)', fontsize=16)\n",
    "\n",
    "    # Farbleiste hinzufügen\n",
    "    cbar = fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.5, aspect=10)\n",
    "    cbar.set_label('Logits', fontsize=14)\n",
    "    \n",
    "    plt.savefig(f'../statistics/featuremaps/group-2/{os.path.basename(img_path)}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Verwende CPU statt GPU, falls der Speicher auf der GPU nicht ausreicht\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and torch.cuda.memory_allocated() < 1e9 else 'cpu')\n",
    "# Modell und Transformationen laden\n",
    "model_latent, norm_type_latent = load_model('Grag2021_latent', 'weights/Grag2021_latent/model_epoch_best.pth', device)\n",
    "transform_latent = get_transform(norm_type_latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmapgenerierung und Abspeichern als Bilder\n",
    "for img in os.listdir('../img-dataset/study/study-group-2/imgs'):\n",
    "    visualize_output_map(model_latent, f'../img-dataset/study/study-group-2/imgs/{img}', transform_latent, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesamtheatmap 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Heatmap in 9 Bereiche aufgeteilt\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "def extract_from_end_until_underscore(input_string):\n",
    "    last_underscore_index = input_string.rfind('_')\n",
    "    if last_underscore_index != -1:\n",
    "        result = input_string[last_underscore_index + 1:]\n",
    "    else:\n",
    "        result = input_string\n",
    "    return result\n",
    "\n",
    "# Lade das Modell\n",
    "def load_model(model_name, model_path, device):\n",
    "    _, _, arch, norm_type, _ = get_method_here(model_name, weights_path=model_path)\n",
    "    model = def_model(arch, model_path, localize=False)\n",
    "    model = model.to(device).eval()\n",
    "    return model, norm_type\n",
    "\n",
    "# Transformationen definieren\n",
    "def get_transform(norm_type):\n",
    "    from normalization import get_list_norm\n",
    "    \n",
    "    transform = []\n",
    "    transform = transform + get_list_norm(norm_type)\n",
    "    return transforms.Compose(transform)\n",
    "\n",
    "# Benutzerdefinierte Colormap definieren\n",
    "def get_custom_cmap(vmin, vmax):\n",
    "    abs_max = max(abs(vmin), abs(vmax))\n",
    "    colors = [(0, 'green'), (0.5, 'white'), (1, 'red')]\n",
    "    cmap_name = 'custom_cmap'\n",
    "    cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "    return cmap, -abs_max, abs_max\n",
    "\n",
    "# Ausgabekarte berechnen und visualisieren\n",
    "def visualize_output_map(model, img_path, transform, device):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    input_img = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Modell ausführen\n",
    "    output = model(input_img).squeeze().cpu().detach().numpy()\n",
    "    print(output.shape)\n",
    "\n",
    "    # Ursprüngliche Heatmap-Größe\n",
    "    original_height, original_width = output.shape\n",
    "\n",
    "    # Ziel-Rastergröße (3x3)\n",
    "    target_height, target_width = 3, 3\n",
    "\n",
    "    # Initialisiere die aggregierte Heatmap\n",
    "    aggregated_output = np.zeros((target_height, target_width))\n",
    "\n",
    "    # Aggregiere die Werte in die Ziel-Rasterbereiche\n",
    "    for i in range(target_height):\n",
    "        for j in range(target_width):\n",
    "            # Bestimme die entsprechenden Bereiche in der ursprünglichen Heatmap\n",
    "            start_y = i * original_height // target_height\n",
    "            end_y = (i + 1) * original_height // target_height\n",
    "            start_x = j * original_width // target_width\n",
    "            end_x = (j + 1) * original_width // target_width\n",
    "\n",
    "            # Summe der Werte in diesem Bereich\n",
    "            aggregated_output[i, j] = np.sum(output[start_y:end_y, start_x:end_x])\n",
    "\n",
    "    # Interpolation der aggregierten Werte auf die Bildgröße (480x640)\n",
    "    interpolated_output = cv2.resize(aggregated_output, (640, 480), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Wertebereich für die Ausgabekarte festlegen\n",
    "    vmin, vmax = aggregated_output.min(), aggregated_output.max()\n",
    "    cmap, adjusted_vmin, adjusted_vmax = get_custom_cmap(vmin, vmax)\n",
    "\n",
    "    # Originalbild und interpolierte Ausgabekarte visualisieren\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(extract_from_end_until_underscore(img_path))\n",
    "\n",
    "    im = ax.imshow(interpolated_output, cmap=cmap, vmin=adjusted_vmin, vmax=adjusted_vmax, alpha=0.5)\n",
    "    \n",
    "    # Farbleiste hinzufügen\n",
    "    cbar = fig.colorbar(im, ax=ax, shrink=0.5, aspect=10)\n",
    "    cbar.set_label('Activation Intensity')\n",
    "    \n",
    "    plt.savefig(f'../statistics/3x3_heatmaps/group-2/{os.path.basename(img_path)}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "# Verwende CPU statt GPU, falls der Speicher auf der GPU nicht ausreicht\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and torch.cuda.memory_allocated() < 1e9 else 'cpu')\n",
    "# Modell und Transformationen laden\n",
    "model_latent, norm_type_latent = load_model('Grag2021_latent', 'weights/Grag2021_latent/model_epoch_best.pth', device)\n",
    "transform_latent = get_transform(norm_type_latent)\n",
    "test_img_path = '../imgs/mixed/01_000000415727.jpg'\n",
    "\n",
    "# Ausgabekarte visualisieren\n",
    "#visualize_output_map(model_latent, test_img_path, transform_latent, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps nach Vorzeichen 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Heatmaps in 9 Bereiche\n",
    "def extract_from_end_until_underscore(input_string):\n",
    "    last_underscore_index = input_string.rfind('_')\n",
    "    if last_underscore_index != -1:\n",
    "        result = input_string[last_underscore_index + 1:]\n",
    "    else:\n",
    "        result = input_string\n",
    "    return result\n",
    "\n",
    "# Lade das Modell\n",
    "def load_model(model_name, model_path, device):\n",
    "    _, _, arch, norm_type, _ = get_method_here(model_name, weights_path=model_path)\n",
    "    model = def_model(arch, model_path, localize=False)\n",
    "    model = model.to(device).eval()\n",
    "    return model, norm_type\n",
    "\n",
    "# Transformationen definieren\n",
    "def get_transform(norm_type):\n",
    "    from normalization import get_list_norm\n",
    "    \n",
    "    transform = []\n",
    "    transform = transform + get_list_norm(norm_type)\n",
    "    return transforms.Compose(transform)\n",
    "\n",
    "# Benutzerdefinierte Colormaps definieren\n",
    "def get_positive_cmap():\n",
    "    colors = [(0, 'white'), (1, 'red')]\n",
    "    cmap_name = 'positive_cmap'\n",
    "    cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "    return cmap\n",
    "\n",
    "def get_negative_cmap():\n",
    "    colors = [(0, 'green'), (1, 'white')]\n",
    "    cmap_name = 'negative_cmap'\n",
    "    cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "    return cmap\n",
    "\n",
    "# Ausgabekarte berechnen und visualisieren\n",
    "def visualize_output_maps(model, img_path, transform, device):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    input_img = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Modell ausführen\n",
    "    output = model(input_img).squeeze().cpu().detach().numpy()\n",
    "    print(output.shape)\n",
    "\n",
    "    # Ursprüngliche Heatmap-Größe\n",
    "    original_height, original_width = output.shape\n",
    "\n",
    "    # Ziel-Rastergröße (3x3)\n",
    "    target_height, target_width = 3, 3\n",
    "\n",
    "    # Initialisiere die aggregierten Heatmaps\n",
    "    aggregated_output_positive = np.zeros((target_height, target_width))\n",
    "    aggregated_output_negative = np.zeros((target_height, target_width))\n",
    "\n",
    "    # Aggregiere die Werte in die Ziel-Rasterbereiche\n",
    "    for i in range(target_height):\n",
    "        for j in range(target_width):\n",
    "            # Bestimme die entsprechenden Bereiche in der ursprünglichen Heatmap\n",
    "            start_y = i * original_height // target_height\n",
    "            end_y = (i + 1) * original_height // target_height\n",
    "            start_x = j * original_width // target_width\n",
    "            end_x = (j + 1) * original_width // target_width\n",
    "\n",
    "            # Summe der positiven Werte in diesem Bereich\n",
    "            positive_values = output[start_y:end_y, start_x:end_x] * (output[start_y:end_y, start_x:end_x] > 0)\n",
    "            aggregated_output_positive[i, j] = np.sum(positive_values)\n",
    "\n",
    "            # Summe der negativen Werte in diesem Bereich\n",
    "            negative_values = output[start_y:end_y, start_x:end_x] * (output[start_y:end_y, start_x:end_x] < 0)\n",
    "            aggregated_output_negative[i, j] = np.sum(negative_values)\n",
    "\n",
    "    # Interpolation der aggregierten Werte auf die Bildgröße (640x480)\n",
    "    interpolated_output_positive = cv2.resize(aggregated_output_positive, (640, 480), interpolation=cv2.INTER_NEAREST)\n",
    "    interpolated_output_negative = cv2.resize(aggregated_output_negative, (640, 480), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Wertebereich für die Ausgabekarten festlegen\n",
    "    abs_max_positive = np.max(aggregated_output_positive)\n",
    "    abs_max_negative = abs(np.min(aggregated_output_negative))\n",
    "    abs_max = max(abs_max_positive, abs_max_negative)\n",
    "\n",
    "    positive_cmap = get_positive_cmap()\n",
    "    negative_cmap = get_negative_cmap()\n",
    "\n",
    "    # Originalbild und interpolierte Ausgabekarten visualisieren\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    # Set the title for the entire figure\n",
    "    plt.figtext(0.5, 0.8, f'Aktivierung der Bildbereiche für {extract_from_end_until_underscore(img_path)}', ha='center', fontsize=18)\n",
    "\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('\"KI-generiert\"', fontsize=14)\n",
    "    im0 = axes[0].imshow(interpolated_output_positive, cmap=positive_cmap, vmin=0, vmax=abs_max, alpha=0.5)\n",
    "    axes[0].set_xticks([640/6, 3*640/6, 5*640/6])\n",
    "    axes[0].set_xticklabels(['A', 'B', 'C'])\n",
    "    axes[0].set_yticks([480/6, 3*480/6, 5*480/6])\n",
    "    axes[0].set_yticklabels(['1', '2', '3'])\n",
    "\n",
    "    axes[1].imshow(image)\n",
    "    axes[1].set_title('\"echt\"', fontsize=14)\n",
    "    im1 = axes[1].imshow(interpolated_output_negative, cmap=negative_cmap, vmin=-abs_max, vmax=0, alpha=0.5)\n",
    "    axes[1].set_xticks([640/6, 3*640/6, 5*640/6])\n",
    "    axes[1].set_xticklabels(['A', 'B', 'C'])\n",
    "    axes[1].set_yticks([480/6, 3*480/6, 5*480/6])\n",
    "    axes[1].set_yticklabels(['1', '2', '3'])\n",
    "\n",
    "    # Set tick parameters for both axes\n",
    "    for ax in axes:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "    # Farbleisten hinzufügen\n",
    "    cbar0 = fig.colorbar(im0, ax=axes[0], shrink=0.5, aspect=10)\n",
    "    cbar0.set_label('Positive Logits', fontsize=12)\n",
    "    cbar0.ax.tick_params(labelsize=12)  # Set fontsize for colorbar ticks\n",
    "\n",
    "    cbar1 = fig.colorbar(im1, ax=axes[1], shrink=0.5, aspect=10)\n",
    "    cbar1.set_label('Negative Logits', fontsize=12)\n",
    "    cbar1.ax.tick_params(labelsize=12)  # Set fontsize for colorbar ticks\n",
    "\n",
    "    # Adjust layout to minimize whitespace\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    # Save the plot before showing, using bbox_inches='tight' to minimize whitespace\n",
    "    save_path = f'../statistics/3x3_heatmaps/group-1/{os.path.basename(img_path)}'\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_heatmaps(model, img_path, transform, device):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    input_img = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Modell ausführen\n",
    "    output = model(input_img).squeeze().cpu().detach().numpy()\n",
    "    print(output.shape)\n",
    "\n",
    "    # Ursprüngliche Heatmap-Größe\n",
    "    original_height, original_width = output.shape\n",
    "\n",
    "    # Ziel-Rastergröße (3x3)\n",
    "    target_height, target_width = 3, 3\n",
    "\n",
    "    # Initialisiere die aggregierten Heatmaps\n",
    "    aggregated_output_positive = np.zeros((target_height, target_width))\n",
    "    aggregated_output_negative = np.zeros((target_height, target_width))\n",
    "\n",
    "    # Aggregiere die Werte in die Ziel-Rasterbereiche\n",
    "    for i in range(target_height):\n",
    "        for j in range(target_width):\n",
    "            # Bestimme die entsprechenden Bereiche in der ursprünglichen Heatmap\n",
    "            start_y = i * original_height // target_height\n",
    "            end_y = (i + 1) * original_height // target_height\n",
    "            start_x = j * original_width // target_width\n",
    "            end_x = (j + 1) * original_width // target_width\n",
    "\n",
    "            # Summe der positiven Werte in diesem Bereich\n",
    "            positive_values = output[start_y:end_y, start_x:end_x] * (output[start_y:end_y, start_x:end_x] > 0)\n",
    "            aggregated_output_positive[i, j] = np.sum(positive_values)\n",
    "\n",
    "            # Summe der negativen Werte in diesem Bereich\n",
    "            negative_values = output[start_y:end_y, start_x:end_x] * (output[start_y:end_y, start_x:end_x] < 0)\n",
    "            aggregated_output_negative[i, j] = np.sum(negative_values)\n",
    "    return (img_path, aggregated_output_positive, aggregated_output_negative)\n",
    "\n",
    "# Verwende CPU statt GPU, falls der Speicher auf der GPU nicht ausreicht\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and torch.cuda.memory_allocated() < 1e9 else 'cpu')\n",
    "# Modell und Transformationen laden\n",
    "model_latent, norm_type_latent = load_model('Grag2021_latent', 'weights/Grag2021_latent/model_epoch_best.pth', device)\n",
    "transform_latent = get_transform(norm_type_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_output_maps(model_latent, f'../img-dataset/study/study-group-2/imgs/02_395343-short-sdxl.jpg', transform_latent, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmapgenerierung und Abspeichern als Bilder\n",
    "for img in os.listdir('../img-dataset/study/study-group-1/imgs'):\n",
    "    visualize_output_maps(model_latent, f'../img-dataset/study/study-group-1/imgs/{img}', transform_latent, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerische Daten der Heatmaps speichern\n",
    "heatmaps_g1 = []\n",
    "heatmaps_g2 = []\n",
    "for img in os.listdir('../img-dataset/study/study-group-1/imgs'):\n",
    "    heatmaps_g1.append(get_heatmaps(model_latent, f'../img-dataset/study/study-group-1/imgs/{img}', transform_latent, device))\n",
    "with open('model_heatmaps_g1.pkl', 'wb') as f:\n",
    "    pickle.dump(heatmaps_g1, f)\n",
    "\n",
    "for img in os.listdir('../img-dataset/study/study-group-2/imgs'):\n",
    "    heatmaps_g2.append(get_heatmaps(model_latent, f'../img-dataset/study/study-group-2/imgs/{img}', transform_latent, device))\n",
    "with open('model_heatmaps_g2.pkl', 'wb') as f:\n",
    "    pickle.dump(heatmaps_g2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellarchitektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from get_method_here import get_method_here, def_model\n",
    "import os\n",
    "\n",
    "# Speicherverwaltung einstellen\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Lade das Modell\n",
    "def load_model(model_name, model_path, device):\n",
    "    _, _, arch, norm_type, _ = get_method_here(model_name, weights_path=model_path)\n",
    "    model = def_model(arch, model_path, localize=False)\n",
    "    model = model.to(device).eval()\n",
    "    return model, norm_type\n",
    "\n",
    "# Verwende CPU statt GPU, falls der Speicher auf der GPU nicht ausreicht\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and torch.cuda.memory_allocated() < 1e9 else 'cpu')\n",
    "\n",
    "# Modell laden\n",
    "model_latent, norm_type_latent = load_model('Grag2021_latent', 'weights/Grag2021_latent/model_epoch_best.pth', device)\n",
    "\n",
    "# Modellarchitektur ausgeben\n",
    "print(\"Modellarchitektur:\")\n",
    "print(model_latent)\n",
    "\n",
    "# Testbild transformieren und durch das Modell laufen lassen\n",
    "test_img_path = '../imgs/mixed/01_000000415727.jpg'\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transformationen definieren\n",
    "def get_transform(norm_type):\n",
    "    from normalization import get_list_norm\n",
    "    transform = []\n",
    "    transform = transform + get_list_norm(norm_type)\n",
    "    return transforms.Compose(transform)\n",
    "\n",
    "transform_latent = get_transform(norm_type_latent)\n",
    "image = Image.open(test_img_path).convert('RGB')\n",
    "input_img = transform_latent(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Erzeuge den Graphen\n",
    "output = model_latent(input_img)\n",
    "dot = make_dot(output, params=dict(model_latent.named_parameters()))\n",
    "\n",
    "# Speichere den Graphen als PDF oder PNG\n",
    "dot.format = 'pdf'\n",
    "dot.render('model_architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
